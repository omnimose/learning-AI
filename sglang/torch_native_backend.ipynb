{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b851f385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import scaled_dot_product_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2667fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from torch.nn.functional import scaled_dot_product_attention\n",
    "\n",
    "def create_test_data_for_extend():\n",
    "    \"\"\"\n",
    "    Create sample data to test _run_sdpa_forward_extend function.\n",
    "    \n",
    "    Scenario: 3 sequences being extended with different configurations\n",
    "    \"\"\"\n",
    "    \n",
    "    # Model configuration\n",
    "    num_heads = 8\n",
    "    head_size = 64\n",
    "    max_total_tokens = 1000\n",
    "    max_num_reqs = 100\n",
    "    max_context_len = 512\n",
    "    \n",
    "    # Batch configuration\n",
    "    num_seqs = 3\n",
    "    seq_lens = torch.tensor([10, 15, 8])                # Total tokens after extension\n",
    "    extend_prefix_lens = torch.tensor([7, 12, 5])       # Already cached tokens\n",
    "    extend_seq_lens = torch.tensor([3, 3, 3])           # New tokens being added\n",
    "    req_pool_indices = torch.tensor([42, 17, 89])       # Memory pool locations\n",
    "    \n",
    "    # Calculate total new tokens\n",
    "    num_tokens = extend_seq_lens.sum().item()  # 3 + 3 + 3 = 9\n",
    "    \n",
    "    print(f\"=== TEST DATA CONFIGURATION ===\")\n",
    "    print(f\"num_seqs: {num_seqs}\")\n",
    "    print(f\"seq_lens: {seq_lens.tolist()}\")\n",
    "    print(f\"extend_prefix_lens: {extend_prefix_lens.tolist()}\")\n",
    "    print(f\"extend_seq_lens: {extend_seq_lens.tolist()}\")\n",
    "    print(f\"total num_tokens: {num_tokens}\")\n",
    "    print(f\"req_pool_indices: {req_pool_indices.tolist()}\")\n",
    "    print()\n",
    "    \n",
    "    # Create query tensor [num_tokens, num_heads, head_size]\n",
    "    query = torch.randn(num_tokens, num_heads, head_size)\n",
    "    \n",
    "    # Mark query tokens with identifiable values for debugging\n",
    "    for i in range(num_tokens):\n",
    "        query[i, :, 0] = i + 100  # First dimension has token ID (100, 101, 102, ...)\n",
    "    \n",
    "    print(f\"Query tensor shape: {query.shape}\")\n",
    "    print(f\"Query token markers (first head, first dim): {query[:, 0, 0].tolist()}\")\n",
    "    print()\n",
    "    \n",
    "    # Create output tensor (same shape as query)\n",
    "    output = torch.zeros_like(query)\n",
    "    \n",
    "    # Create global KV cache [max_total_tokens, num_heads, head_size]\n",
    "    k_cache = torch.randn(max_total_tokens, num_heads, head_size)\n",
    "    v_cache = torch.randn(max_total_tokens, num_heads, head_size)\n",
    "    \n",
    "    # Mark cache entries with identifiable values\n",
    "    for i in range(max_total_tokens):\n",
    "        k_cache[i, :, 0] = i + 1000  # Key cache markers (1000, 1001, 1002, ...)\n",
    "        v_cache[i, :, 0] = i + 2000  # Value cache markers (2000, 2001, 2002, ...)\n",
    "    \n",
    "    # Create req_to_token mapping [max_num_reqs, max_context_len]\n",
    "    req_to_token = torch.zeros(max_num_reqs, max_context_len, dtype=torch.long)\n",
    "    \n",
    "    # Set up token mappings for our test sequences\n",
    "    # Sequence 0: pool index 42, uses tokens 100-109 in cache\n",
    "    req_to_token[42, :10] = torch.arange(100, 110)\n",
    "    \n",
    "    # Sequence 1: pool index 17, uses tokens 200-214 in cache  \n",
    "    req_to_token[17, :15] = torch.arange(200, 215)\n",
    "    \n",
    "    # Sequence 2: pool index 89, uses tokens 300-307 in cache\n",
    "    req_to_token[89, :8] = torch.arange(300, 308)\n",
    "    \n",
    "    print(f\"=== TOKEN MAPPINGS ===\")\n",
    "    print(f\"Seq 0 (pool {req_pool_indices[0]}): cache tokens {req_to_token[42, :10].tolist()}\")\n",
    "    print(f\"Seq 1 (pool {req_pool_indices[1]}): cache tokens {req_to_token[17, :15].tolist()}\")\n",
    "    print(f\"Seq 2 (pool {req_pool_indices[2]}): cache tokens {req_to_token[89, :8].tolist()}\")\n",
    "    print()\n",
    "    \n",
    "    # Set scaling factor\n",
    "    scaling = 1.0 / math.sqrt(head_size)\n",
    "    \n",
    "    return {\n",
    "        'query': query,\n",
    "        'output': output,\n",
    "        'k_cache': k_cache,\n",
    "        'v_cache': v_cache,\n",
    "        'req_to_token': req_to_token,\n",
    "        'req_pool_indices': req_pool_indices,\n",
    "        'seq_lens': seq_lens,\n",
    "        'extend_prefix_lens': extend_prefix_lens,\n",
    "        'extend_seq_lens': extend_seq_lens,\n",
    "        'scaling': scaling,\n",
    "        'enable_gqa': False,\n",
    "        'causal': True\n",
    "    }\n",
    "\n",
    "def test_run_sdpa_forward_extend():\n",
    "    \"\"\"Test the _run_sdpa_forward_extend function with sample data.\"\"\"\n",
    "    \n",
    "    # Get test data\n",
    "    test_data = create_test_data_for_extend()\n",
    "    \n",
    "    # Extract parameters\n",
    "    query = test_data['query']\n",
    "    output = test_data['output']\n",
    "    k_cache = test_data['k_cache']\n",
    "    v_cache = test_data['v_cache']\n",
    "    req_to_token = test_data['req_to_token']\n",
    "    req_pool_indices = test_data['req_pool_indices']\n",
    "    seq_lens = test_data['seq_lens']\n",
    "    extend_prefix_lens = test_data['extend_prefix_lens']\n",
    "    extend_seq_lens = test_data['extend_seq_lens']\n",
    "    scaling = test_data['scaling']\n",
    "    enable_gqa = test_data['enable_gqa']\n",
    "    causal = test_data['causal']\n",
    "    \n",
    "    print(\"=== BEFORE PROCESSING ===\")\n",
    "    print(f\"Output tensor (should be zeros): {output[:3, 0, 0].tolist()}\")\n",
    "    print()\n",
    "    \n",
    "    # Simulate the _run_sdpa_forward_extend function\n",
    "    # [num_tokens, num_heads, head_size] -> [num_heads, num_tokens, head_size]\n",
    "    query_reshaped = query.movedim(0, query.dim() - 2)\n",
    "    \n",
    "    start_q, start_kv = 0, 0\n",
    "    \n",
    "    for seq_idx in range(seq_lens.shape[0]):\n",
    "        print(f\"=== PROCESSING SEQUENCE {seq_idx} ===\")\n",
    "        \n",
    "        extend_seq_len_q = extend_seq_lens[seq_idx].item()\n",
    "        prefill_seq_len_q = extend_prefix_lens[seq_idx].item()\n",
    "        seq_len_kv = seq_lens[seq_idx].item()\n",
    "        end_q = start_q + extend_seq_len_q\n",
    "        end_kv = start_kv + seq_len_kv\n",
    "        \n",
    "        print(f\"extend_seq_len_q: {extend_seq_len_q}\")\n",
    "        print(f\"prefill_seq_len_q: {prefill_seq_len_q}\")\n",
    "        print(f\"seq_len_kv: {seq_len_kv}\")\n",
    "        print(f\"Query range: [{start_q}:{end_q}]\")\n",
    "        \n",
    "        # Extract query for this sequence\n",
    "        per_req_query = query_reshaped[:, start_q:end_q, :]\n",
    "        print(f\"per_req_query shape: {per_req_query.shape}\")\n",
    "        print(f\"per_req_query markers: {per_req_query[0, :, 0].tolist()}\")\n",
    "        \n",
    "        # Create redundant query tensor\n",
    "        per_req_query_redundant = torch.zeros(\n",
    "            (per_req_query.shape[0], seq_len_kv, per_req_query.shape[2]),\n",
    "            dtype=per_req_query.dtype,\n",
    "            device=per_req_query.device,\n",
    "        )\n",
    "        \n",
    "        # Place new queries at correct positions  \n",
    "        per_req_query_redundant[:, prefill_seq_len_q:, :] = per_req_query\n",
    "        print(f\"per_req_query_redundant shape: {per_req_query_redundant.shape}\")\n",
    "        print(f\"Redundant query markers: {per_req_query_redundant[0, :, 0].tolist()}\")\n",
    "        \n",
    "        # Get key and value from cache\n",
    "        req_pool_idx = req_pool_indices[seq_idx].item()\n",
    "        per_req_tokens = req_to_token[req_pool_idx, :seq_len_kv]\n",
    "        print(f\"req_pool_idx: {req_pool_idx}\")\n",
    "        print(f\"per_req_tokens: {per_req_tokens.tolist()}\")\n",
    "        \n",
    "        per_req_key = k_cache[per_req_tokens].movedim(0, query.dim() - 2)\n",
    "        per_req_value = v_cache[per_req_tokens].movedim(0, query.dim() - 2)\n",
    "        print(f\"per_req_key shape: {per_req_key.shape}\")\n",
    "        print(f\"Key markers: {per_req_key[0, :, 0].tolist()}\")\n",
    "        print(f\"Value markers: {per_req_value[0, :, 0].tolist()}\")\n",
    "        \n",
    "        # Run attention\n",
    "        per_req_out_redundant = (\n",
    "            scaled_dot_product_attention(\n",
    "                per_req_query_redundant.unsqueeze(0),\n",
    "                per_req_key.unsqueeze(0),\n",
    "                per_req_value.unsqueeze(0),\n",
    "                scale=scaling,\n",
    "                is_causal=causal,\n",
    "            )\n",
    "            .squeeze(0)\n",
    "            .movedim(query.dim() - 2, 0)\n",
    "        )\n",
    "        \n",
    "        print(f\"per_req_out_redundant shape: {per_req_out_redundant.shape}\")\n",
    "        print(f\"Output markers before extraction: {per_req_out_redundant[:, 0, 0].tolist()}\")\n",
    "        \n",
    "        # Extract relevant outputs\n",
    "        relevant_output = per_req_out_redundant[prefill_seq_len_q:, :, :]\n",
    "        output[start_q:end_q, :, :] = relevant_output\n",
    "        \n",
    "        print(f\"Extracted output shape: {relevant_output.shape}\")\n",
    "        print(f\"Placed in output[{start_q}:{end_q}]\")\n",
    "        print(f\"Output after placement: {output[start_q:end_q, 0, 0].tolist()}\")\n",
    "        print()\n",
    "        \n",
    "        start_q, start_kv = end_q, end_kv\n",
    "    \n",
    "    print(\"=== FINAL RESULTS ===\")\n",
    "    print(f\"Final output shape: {output.shape}\")\n",
    "    print(f\"Output sample (first head, first dim): {output[:, 0, 0].tolist()}\")\n",
    "    print()\n",
    "    \n",
    "    # Verify output is non-zero (attention worked)\n",
    "    output_norm = torch.norm(output)\n",
    "    print(f\"Output tensor norm: {output_norm:.4f}\")\n",
    "    \n",
    "    if output_norm > 0:\n",
    "        print(\"✅ Test PASSED - Output is non-zero, attention computation worked\")\n",
    "    else:\n",
    "        print(\"❌ Test FAILED - Output is zero, something went wrong\")\n",
    "    \n",
    "    return output\n",
    "\n",
    "def visualize_attention_pattern_correct():\n",
    "    \"\"\"\n",
    "    Properly visualize attention patterns without tensor dimension issues.\n",
    "    \n",
    "    The key insight: we need to avoid zero queries that cause NaN when combined with causal masking.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=== CORRECTED ATTENTION PATTERN VISUALIZATION ===\")\n",
    "    \n",
    "    # Configuration\n",
    "    extend_prefix_len = 2  # 2 cached tokens\n",
    "    extend_seq_len = 2     # 2 new tokens  \n",
    "    seq_len_kv = 4         # Total tokens in sequence\n",
    "    \n",
    "    # Create meaningful queries (non-zero for positions that will be used)\n",
    "    # Shape: [seq_len, head_dim] where we only care about the new token positions\n",
    "    query_redundant = torch.tensor([\n",
    "        [0.0],  # Position 0: cached (will be masked anyway)\n",
    "        [0.0],  # Position 1: cached (will be masked anyway)  \n",
    "        [1.0],  # Position 2: new token with query\n",
    "        [2.0],  # Position 3: new token with query\n",
    "    ])\n",
    "    \n",
    "    # Keys and values\n",
    "    k_cache = torch.tensor([\n",
    "        [1.0],  # Key for position 0\n",
    "        [1.0],  # Key for position 1\n",
    "        [1.0],  # Key for position 2  \n",
    "        [1.0],  # Key for position 3\n",
    "    ])\n",
    "    \n",
    "    v_cache = torch.tensor([\n",
    "        [10.0],  # Value for position 0\n",
    "        [20.0],  # Value for position 1\n",
    "        [30.0],  # Value for position 2\n",
    "        [40.0],  # Value for position 3\n",
    "    ])\n",
    "    \n",
    "    print(f\"Query (redundant): {query_redundant.squeeze().tolist()}\")\n",
    "    print(f\"Key cache: {k_cache.squeeze().tolist()}\")  \n",
    "    print(f\"Value cache: {v_cache.squeeze().tolist()}\")\n",
    "    print(f\"Extend prefix length: {extend_prefix_len}\")\n",
    "    print(f\"New token positions: {extend_prefix_len} onwards\")\n",
    "    print()\n",
    "    \n",
    "    # Compute raw attention scores: Q @ K^T\n",
    "    scores = torch.matmul(query_redundant, k_cache.transpose(-2, -1))  # [4, 4]\n",
    "    print(f\"Raw scores shape: {scores.shape}\")\n",
    "    print(\"Raw scores (Q @ K^T):\")\n",
    "    for i, row in enumerate(scores.tolist()):\n",
    "        print(f\"  Position {i}: {row}\")\n",
    "    print()\n",
    "    \n",
    "    # Create causal mask: upper triangular with -inf\n",
    "    causal_mask = torch.triu(torch.ones(4, 4), diagonal=1) * float('-inf')\n",
    "    print(\"Causal mask:\")\n",
    "    for i, row in enumerate(causal_mask.tolist()):\n",
    "        print(f\"  Position {i}: {[f'{x:.0f}' if x != float('-inf') else '-∞' for x in row]}\")\n",
    "    print()\n",
    "    \n",
    "    # Apply causal mask\n",
    "    scores_masked = scores + causal_mask\n",
    "    print(\"Scores after causal masking:\")\n",
    "    for i, row in enumerate(scores_masked.tolist()):\n",
    "        formatted_row = []\n",
    "        for x in row:\n",
    "            if x == float('-inf'):\n",
    "                formatted_row.append('-∞')\n",
    "            elif math.isnan(x):\n",
    "                formatted_row.append('NaN')  \n",
    "            else:\n",
    "                formatted_row.append(f'{x:.1f}')\n",
    "        print(f\"  Position {i}: {formatted_row}\")\n",
    "    print()\n",
    "    \n",
    "    # Apply softmax to get attention weights\n",
    "    attn_weights = torch.softmax(scores_masked, dim=-1)\n",
    "    print(\"Attention weights (after softmax):\")\n",
    "    for i, row in enumerate(attn_weights.tolist()):\n",
    "        formatted_row = []\n",
    "        for x in row:\n",
    "            if math.isnan(x):\n",
    "                formatted_row.append('NaN')\n",
    "            else:\n",
    "                formatted_row.append(f'{x:.3f}')\n",
    "        print(f\"  Position {i}: {formatted_row}\")\n",
    "    print()\n",
    "    \n",
    "    # Compute final output: attention_weights @ V\n",
    "    output = torch.matmul(attn_weights, v_cache)  # [4, 1]\n",
    "    print(f\"Final output shape: {output.shape}\")\n",
    "    print(\"Final output (attention @ V):\")\n",
    "    for i, val in enumerate(output.squeeze().tolist()):\n",
    "        if math.isnan(val):\n",
    "            print(f\"  Position {i}: NaN\")\n",
    "        else:\n",
    "            print(f\"  Position {i}: {val:.2f}\")\n",
    "    print()\n",
    "    \n",
    "    # Extract only the outputs for new tokens (what the extend function would return)\n",
    "    new_token_outputs = output[extend_prefix_len:]\n",
    "    print(f\"New token outputs (positions {extend_prefix_len}+): {new_token_outputs.squeeze().tolist()}\")\n",
    "    \n",
    "    print(\"\\n=== EXPLANATION ===\")\n",
    "    print(\"1. Positions 0,1: Cached tokens (prefix)\")\n",
    "    print(\"2. Positions 2,3: New tokens being processed\")\n",
    "    print(\"3. Causal mask ensures:\")\n",
    "    print(\"   - Position 0: Only attends to itself\")\n",
    "    print(\"   - Position 1: Attends to positions 0,1\") \n",
    "    print(\"   - Position 2: Attends to positions 0,1,2\")\n",
    "    print(\"   - Position 3: Attends to positions 0,1,2,3\")\n",
    "    print(\"4. Only outputs for positions 2,3 are used (new tokens)\")\n",
    "    \n",
    "    # Show that this matches the extend function behavior\n",
    "    print(\"\\n=== EXTEND FUNCTION SIMULATION ===\")\n",
    "    print(\"This is exactly what _run_sdpa_forward_extend does:\")\n",
    "    print(\"1. Creates redundant query with new tokens at correct positions\")\n",
    "    print(\"2. Uses full KV cache for the sequence\") \n",
    "    print(\"3. Applies causal attention\")\n",
    "    print(\"4. Extracts outputs only for new token positions\")\n",
    "\n",
    "def simple_working_example():\n",
    "    \"\"\"A simple example that definitely works without any issues.\"\"\"\n",
    "    \n",
    "    print(\"=== SIMPLE WORKING EXAMPLE ===\")\n",
    "    \n",
    "    # Use PyTorch's SDPA directly (like the real function does)\n",
    "    batch_size = 1\n",
    "    num_heads = 2\n",
    "    seq_len = 4  \n",
    "    head_dim = 8\n",
    "    \n",
    "    # Create test tensors with proper dimensions\n",
    "    query = torch.randn(batch_size, num_heads, seq_len, head_dim)\n",
    "    key = torch.randn(batch_size, num_heads, seq_len, head_dim)  \n",
    "    value = torch.randn(batch_size, num_heads, seq_len, head_dim)\n",
    "    \n",
    "    print(f\"Query shape: {query.shape}\")\n",
    "    print(f\"Key shape: {key.shape}\")\n",
    "    print(f\"Value shape: {value.shape}\")\n",
    "    \n",
    "    # Run attention with causal masking\n",
    "    output = scaled_dot_product_attention(\n",
    "        query, key, value,\n",
    "        is_causal=True,\n",
    "        scale=1.0 / math.sqrt(head_dim)\n",
    "    )\n",
    "    \n",
    "    print(f\"Output shape: {output.shape}\")\n",
    "    print(f\"Output norm: {torch.norm(output):.4f}\")\n",
    "    \n",
    "    # Simulate extracting new tokens (last 2 positions)\n",
    "    extend_prefix_len = 2\n",
    "    new_token_outputs = output[:, :, extend_prefix_len:, :]\n",
    "    print(f\"New token outputs shape: {new_token_outputs.shape}\")\n",
    "    print(f\"New token outputs norm: {torch.norm(new_token_outputs):.4f}\")\n",
    "    \n",
    "    print(\"✅ Simple example completed successfully!\")\n",
    "    print(\"This demonstrates that SDPA works correctly with proper tensor shapes.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the simple working example first\n",
    "    simple_working_example()\n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # Run the corrected visualization\n",
    "    visualize_attention_pattern_correct()\n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # Run the main test\n",
    "    test_run_sdpa_forward_extend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fac9cf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TEST DATA CONFIGURATION ===\n",
      "num_seqs: 3\n",
      "seq_lens: [10, 15, 8]\n",
      "extend_prefix_lens: [7, 12, 5]\n",
      "extend_seq_lens: [3, 3, 3]\n",
      "total num_tokens: 9\n",
      "req_pool_indices: [42, 17, 89]\n",
      "\n",
      "Query tensor shape: torch.Size([9, 8, 64])\n",
      "Query token markers (first head, first dim): [100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0]\n",
      "\n",
      "=== TOKEN MAPPINGS ===\n",
      "Seq 0 (pool 42): cache tokens [100, 101, 102, 103, 104, 105, 106, 107, 108, 109]\n",
      "Seq 1 (pool 17): cache tokens [200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214]\n",
      "Seq 2 (pool 89): cache tokens [300, 301, 302, 303, 304, 305, 306, 307]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testdata = create_test_data_for_extend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e983171e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000e+02, -1.6576e+00, -2.0029e-02, -4.2802e-01,  1.3332e+00,\n",
       "         9.9924e-01, -8.8784e-01, -4.4433e-01, -5.4830e-01,  5.9202e-01,\n",
       "         8.4495e-01, -8.9862e-01, -2.5020e-02, -7.3002e-01, -2.1434e+00,\n",
       "         6.3140e-01,  5.9199e-01,  2.7241e+00,  1.6477e+00,  8.3054e-01,\n",
       "         1.6440e+00, -1.1733e+00,  6.0557e-01,  1.8598e-01, -1.8381e+00,\n",
       "         5.8024e-01,  4.4517e-01, -2.8377e-01, -1.4314e+00,  1.1170e-02,\n",
       "         1.3062e+00, -1.5280e+00, -7.7959e-01, -9.0410e-01,  1.5533e+00,\n",
       "         6.5476e-01, -1.0017e+00, -3.6100e-01,  1.6596e+00, -6.9675e-01,\n",
       "        -6.5668e-02,  8.1829e-01, -1.2362e+00, -8.3845e-01,  3.2537e-01,\n",
       "        -1.8887e-01,  1.4897e-01, -9.9384e-01,  7.2069e-01,  1.8491e+00,\n",
       "        -9.2455e-01,  6.9416e-01, -1.2503e+00, -3.9238e-01,  1.7303e+00,\n",
       "        -2.0750e+00, -1.0172e+00, -4.9965e-01, -7.6738e-01,  1.5230e+00,\n",
       "         6.1120e-01,  4.1065e-01, -7.2143e-01,  1.1637e+00])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = testdata['query']\n",
    "q[0, 1, :]  # Access the first element in the first head and first dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42ec042f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_q: 0, end_q: 3\n",
      "per_req_query shape: torch.Size([8, 3, 64])\n",
      "per_req_query_redudant shape: torch.Size([8, 10, 64])\n",
      "per_req_query_redudant after assignment shape: torch.Size([8, 10, 64])\n",
      "start_q: 3, end_q: 6\n",
      "per_req_query shape: torch.Size([8, 3, 64])\n",
      "per_req_query_redudant shape: torch.Size([8, 15, 64])\n",
      "per_req_query_redudant after assignment shape: torch.Size([8, 15, 64])\n",
      "start_q: 6, end_q: 9\n",
      "per_req_query shape: torch.Size([8, 3, 64])\n",
      "per_req_query_redudant shape: torch.Size([8, 8, 64])\n",
      "per_req_query_redudant after assignment shape: torch.Size([8, 8, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.1070e+03, -1.7710e+00, -1.1017e+00,  ..., -4.2823e-01,\n",
       "           1.4145e-01, -2.0578e+00],\n",
       "         [ 2.1070e+03,  1.5543e-01,  1.3160e-01,  ...,  4.8716e-01,\n",
       "           9.3702e-01,  1.3232e-01],\n",
       "         [ 2.1070e+03,  2.2299e-01,  1.4251e-02,  ..., -3.9241e-01,\n",
       "          -9.8241e-01,  5.5761e-02],\n",
       "         ...,\n",
       "         [ 2.1070e+03,  8.1138e-01, -1.0179e+00,  ...,  9.7894e-01,\n",
       "          -7.9975e-01, -8.9252e-01],\n",
       "         [ 2.1070e+03,  1.9310e+00, -6.5271e-01,  ...,  5.2144e-01,\n",
       "          -3.0845e-01, -3.9937e-01],\n",
       "         [ 2.1070e+03, -8.9899e-01, -2.8282e-02,  ...,  2.2493e+00,\n",
       "           4.6407e-01, -1.1943e+00]],\n",
       "\n",
       "        [[ 2.1080e+03,  1.1631e+00,  9.3131e-01,  ...,  9.6877e-01,\n",
       "          -5.1081e-01, -1.7506e+00],\n",
       "         [ 2.1080e+03, -5.8837e-01, -5.5931e-01,  ..., -4.2122e-01,\n",
       "          -1.2030e-01,  8.3382e-01],\n",
       "         [ 2.1080e+03,  3.8540e-01, -5.2342e-02,  ...,  2.2130e+00,\n",
       "          -5.2050e-01, -5.6921e-01],\n",
       "         ...,\n",
       "         [ 2.1080e+03,  1.9078e+00,  8.5422e-02,  ..., -8.8960e-01,\n",
       "           5.3803e-01, -1.3845e+00],\n",
       "         [ 2.1080e+03,  3.5212e-02,  3.4514e-01,  ..., -3.8371e-01,\n",
       "           1.9395e-01,  6.0892e-01],\n",
       "         [ 2.1080e+03, -1.7624e+00,  3.4297e-01,  ...,  4.4613e-01,\n",
       "           7.0775e-01,  7.7757e-01]],\n",
       "\n",
       "        [[ 2.1090e+03, -5.1478e-01,  7.1301e-01,  ...,  1.0259e+00,\n",
       "          -1.6445e+00, -4.3856e-01],\n",
       "         [ 2.1090e+03,  1.1627e+00,  1.4340e-02,  ..., -3.3341e-01,\n",
       "          -2.4828e-01, -2.2452e-01],\n",
       "         [ 2.1090e+03, -7.2029e-02, -6.2146e-01,  ...,  1.1885e+00,\n",
       "           7.6897e-01,  2.7541e-01],\n",
       "         ...,\n",
       "         [ 2.1090e+03,  1.7910e+00, -1.0506e+00,  ...,  1.6791e+00,\n",
       "          -6.7729e-03, -5.7719e-01],\n",
       "         [ 2.1090e+03, -1.9308e+00, -5.8088e-01,  ..., -3.8565e-01,\n",
       "           1.5949e-01, -9.4311e-01],\n",
       "         [ 2.1090e+03,  6.0095e-01, -1.4037e-04,  ...,  1.1243e+00,\n",
       "          -1.6204e-02, -1.0366e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 2.3050e+03, -7.6403e-02,  6.1560e-01,  ...,  4.2751e-02,\n",
       "           1.1008e+00,  9.6517e-01],\n",
       "         [ 2.3050e+03,  4.1542e-01, -4.5352e-01,  ...,  2.0406e+00,\n",
       "           1.2705e+00, -2.6073e-01],\n",
       "         [ 2.3050e+03, -7.6536e-01, -1.2600e+00,  ...,  3.1358e-01,\n",
       "          -1.2703e+00,  5.4326e-01],\n",
       "         ...,\n",
       "         [ 2.3050e+03,  2.2290e-01,  1.5344e-01,  ..., -1.4058e-01,\n",
       "           8.3305e-02,  7.9759e-01],\n",
       "         [ 2.3050e+03, -1.0634e+00,  1.9440e+00,  ..., -2.3108e-02,\n",
       "          -3.2933e-01,  6.5075e-01],\n",
       "         [ 2.3050e+03,  4.4842e-01,  8.9490e-02,  ...,  5.6924e-01,\n",
       "          -7.8167e-01,  1.9660e-01]],\n",
       "\n",
       "        [[ 2.3060e+03, -1.6968e-01, -1.0103e+00,  ..., -9.6821e-02,\n",
       "          -9.4408e-01, -1.6725e+00],\n",
       "         [ 2.3060e+03, -2.1120e+00,  1.3464e+00,  ...,  3.4182e-01,\n",
       "          -1.4757e+00,  1.2673e+00],\n",
       "         [ 2.3060e+03, -1.2926e+00,  1.5036e-01,  ..., -1.2132e+00,\n",
       "          -1.9224e+00,  1.2531e+00],\n",
       "         ...,\n",
       "         [ 2.3060e+03,  1.4017e-01, -1.1969e+00,  ..., -1.4019e+00,\n",
       "          -1.9966e+00, -5.0398e-01],\n",
       "         [ 2.3060e+03,  6.6054e-01,  3.4992e-01,  ...,  2.0130e+00,\n",
       "          -1.4138e+00,  5.6182e-01],\n",
       "         [ 2.3060e+03, -6.6071e-01, -1.2509e-01,  ..., -2.0713e+00,\n",
       "          -7.3790e-01,  3.9548e-01]],\n",
       "\n",
       "        [[ 2.3070e+03,  3.7723e-03, -3.2376e-01,  ..., -8.6301e-01,\n",
       "           1.1171e+00,  7.1906e-01],\n",
       "         [ 2.3070e+03,  2.0586e-01,  1.7998e-01,  ..., -1.5861e-01,\n",
       "          -1.5931e-02, -1.6796e+00],\n",
       "         [ 2.3070e+03,  2.9371e-01, -1.2665e+00,  ..., -7.6051e-01,\n",
       "          -1.2430e+00, -1.9786e+00],\n",
       "         ...,\n",
       "         [ 2.3070e+03, -1.0629e+00, -7.6003e-01,  ..., -2.7305e-04,\n",
       "           2.4634e+00, -1.0123e+00],\n",
       "         [ 2.3070e+03,  7.9624e-01, -8.1141e-01,  ...,  1.0282e+00,\n",
       "          -4.3110e-01,  1.2184e+00],\n",
       "         [ 2.3070e+03, -4.7438e-01, -7.2216e-01,  ...,  1.1694e-01,\n",
       "          -1.0811e+00, -2.7246e-01]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_run_sdpa_forward_extend(\n",
    "    query=testdata['query'],\n",
    "    output=testdata['output'],\n",
    "    k_cache=testdata['k_cache'],\n",
    "    v_cache=testdata['v_cache'],\n",
    "    req_to_token=testdata['req_to_token'],\n",
    "    req_pool_indices=testdata['req_pool_indices'],\n",
    "    seq_lens=testdata['seq_lens'],\n",
    "    extend_prefix_lens=testdata['extend_prefix_lens'],\n",
    "    extend_seq_lens=testdata['extend_seq_lens'],\n",
    "    scaling=testdata['scaling'],\n",
    "    enable_gqa=testdata['enable_gqa'],\n",
    "    causal=testdata['causal'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99d60977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 8, 64])\n",
      "torch.Size([8, 9, 64])\n"
     ]
    }
   ],
   "source": [
    "query = testdata['query']\n",
    "print(query.shape) \n",
    "query = query.movedim(0, query.dim() - 2)  \n",
    "print(query.shape)  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52f38f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 15,  8])\n",
      "torch.Size([3])\n",
      "3\n",
      "tensor(10)\n"
     ]
    }
   ],
   "source": [
    "seq_lens= testdata['seq_lens']\n",
    "print(seq_lens)\n",
    "print(seq_lens.shape)\n",
    "print(seq_lens.shape[0])  # Number of sequences\n",
    "\n",
    "\n",
    "seq_len_kv = seq_lens[0]  # Example for the first sequence\n",
    "print(seq_len_kv)  # Should print the length of the first sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2bb74adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 3, 3])\n",
      "torch.Size([3])\n",
      "tensor(3)\n",
      "tensor(3)\n"
     ]
    }
   ],
   "source": [
    "extend_seq_lens = testdata['extend_seq_lens']\n",
    "print(extend_seq_lens)\n",
    "print(extend_seq_lens.shape)\n",
    "print(extend_seq_lens[0]) # Number of sequences\n",
    "\n",
    "\n",
    "extend_seq_len_q = extend_seq_lens[0]  # Example for the first sequence\n",
    "start_q = 0\n",
    "end_q = start_q + extend_seq_len_q\n",
    "print(end_q)  # Should print the length of the first sequence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
