{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor `x`:\n",
      "tensor([[[ 1.,  2.],\n",
      "         [ 3.,  4.],\n",
      "         [ 5.,  6.]],\n",
      "\n",
      "        [[ 7.,  8.],\n",
      "         [ 9., 10.],\n",
      "         [11., 12.]]])\n"
     ]
    }
   ],
   "source": [
    "B, T, C = 2, 3, 2  # Batch size = 2, Time steps = 3, Feature size = 2\n",
    "\n",
    "# Example tensor `x`\n",
    "x = torch.tensor([\n",
    "    [[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]],    # Batch 1\n",
    "    [[7.0, 8.0], [9.0, 10.0], [11.0, 12.0]]  # Batch 2\n",
    "])\n",
    "\n",
    "print(\"Input tensor `x`:\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words\n",
    "xbow = torch.zeros((B,T,C))\n",
    "print(\"xbow:\")\n",
    "print(xbow)\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "            xprev = x[b,:t+1]\n",
    "            print(\"xprev:\")\n",
    "            print(xprev)\n",
    "            xbow[b,t] = torch.mean(xprev,0)\n",
    "            print(\"xbow:\")\n",
    "            print(xbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_sum = torch.cumsum(x, dim=1)\n",
    "print(\"cumulative_sum:\")\n",
    "print(cumulative_sum)\n",
    "time_indices = torch.arange(1, T+1, device=x.device).view(1, T, 1)\n",
    "print(\"time_indices:\")\n",
    "print(time_indices)\n",
    "xbow2 = cumulative_sum / time_indices\n",
    "print(\"xbow2:\")\n",
    "print(xbow2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "T, C = 8, 32\n",
    "x = torch.randn(T, C)\n",
    "\n",
    "head_size = 8\n",
    "query = nn.Linear(C, head_size)\n",
    "key = nn.Linear(C, head_size)\n",
    "value = nn.Linear(C, head_size)\n",
    "\n",
    "q = query(x)\n",
    "k = key(x)\n",
    "\n",
    "wei = q @ k.transpose(-2, -1)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T), diagonal=0)\n",
    "\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"wei:\")\n",
    "print(wei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tril:\")\n",
    "print(tril)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out:\n",
      "tensor([[ 0.0649,  0.1602, -0.0311,  0.6902, -0.7329, -0.5998, -0.5210, -0.2716],\n",
      "        [-0.0886, -0.0320, -0.0311,  0.7142, -0.2816,  0.0311, -0.1482, -0.1849],\n",
      "        [-0.2431,  0.2085, -0.0192,  0.6746, -0.3607,  0.3686, -0.2317, -0.3600],\n",
      "        [-0.2869, -0.1572, -0.0683,  0.7051,  0.1820,  0.8295,  0.2040, -0.0929],\n",
      "        [ 0.1469,  0.0730, -0.2744,  0.5075, -0.3719, -0.0090, -0.4512,  0.1519],\n",
      "        [-0.0554,  0.3178, -0.1247,  0.4949, -0.1455,  0.5526, -0.1992, -0.0362],\n",
      "        [-0.0352,  0.1734, -0.1119,  0.5989, -0.1932,  0.3782, -0.2868,  0.0249],\n",
      "        [-0.3431,  0.4761, -0.1086,  0.6183, -0.0982,  0.5465,  0.0169, -0.0715]],\n",
      "       grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"out:\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1: tensor([0.1723, 0.1276, 0.2104, 0.2326, 0.2570])\n",
      "scaled up x: tensor([ 0.8000, -1.6000,  2.4000,  3.2000,  4.0000])\n",
      "v2: tensor([0.0240, 0.0022, 0.1191, 0.2650, 0.5897])\n",
      "q.var: tensor(1.0746)\n",
      "k.var: tensor(0.9732)\n",
      "wei.var: tensor(72.8887)\n",
      "scaled wei.var: tensor(1.1389)\n"
     ]
    }
   ],
   "source": [
    "# scaled attention score\n",
    "\n",
    "# softmax saturates to the max value\n",
    "x = torch.tensor([0.1, -0.2, 0.3, 0.4, 0.5])\n",
    "v1 = torch.softmax(x, dim=0)\n",
    "print(\"v1:\", v1)\n",
    "\n",
    "x = x * 8\n",
    "print(\"scaled up x:\", x)\n",
    "v2 = torch.softmax(x, dim=0)\n",
    "\n",
    "# softmax sharps to the max value\n",
    "print(\"v2:\", v2)\n",
    "\n",
    "# keeps the variance stable\n",
    "T, C = 8, 32\n",
    "x = torch.randn(T, C)\n",
    "\n",
    "head_size = 64\n",
    "q = torch.randn(C, head_size)\n",
    "k = torch.randn(C, head_size)\n",
    "\n",
    "# q and v have the similar variance which is close to 1\n",
    "print(\"q.var:\", q.var()) \n",
    "print(\"k.var:\", k.var())\n",
    "\n",
    "wei = q @ k.transpose(-2, -1) \n",
    "print(\"wei.var:\", wei.var())\n",
    "\n",
    "# scaled attention score's variance is close to 1 also\n",
    "wei = wei / (head_size ** 0.5)\n",
    "print(\"scaled wei.var:\", wei.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, block_size, n_embd, head_size):\n",
    "        print(f\"block_size:{block_size}, n_embd: {n_embd}, head_size: {head_size}\")\n",
    "        \n",
    "        self.block_size = block_size\n",
    "        self.n_embd = n_embd\n",
    "        self.head_size = head_size\n",
    "\n",
    "        super().__init__()\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size), diagonal=0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        assert T == self.block_size\n",
    "        assert C == self.n_embd\n",
    "\n",
    "        q = self.query(x) # (B, block_size, head_size)\n",
    "        k = self.key(x) # (B, block_size, head_size)\n",
    "\n",
    "        wei = q @ k.transpose(-2, -1) # (B, block_size, block_size)\n",
    "        wei = wei / (self.head_size ** 0.5)\n",
    "        wei = wei.masked_fill(self.tril == 0, float('-inf'))\n",
    "        #print(\"masked wei:\")\n",
    "        #print(wei)\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        #print(\"softmax wei:\")\n",
    "        #print(wei)\n",
    "\n",
    "        v = self.value(x) # (B, block_size, head_size)\n",
    "        out = wei @ v # (B, block_size, head_size)\n",
    "        #print(\"out.shape:\", out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B, T, C= 4, 8, 32\n",
    "block_size = 8\n",
    "n_embd = 32\n",
    "head_size = 8\n",
    "\n",
    "x = torch.randn(B, T, C)\n",
    "head = Head(block_size, n_embd, head_size)\n",
    "out = head(x)\n",
    "print(\"out:\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, block_size, n_embd, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.heads = nn.ModuleList([Head(block_size, n_embd, head_size) for _ in range(n_head)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        head_out = [head(x) for head in self.heads]\n",
    "        print(type(head_out))\n",
    "        out = torch.cat(head_out, dim=-1)\n",
    "        print(\"out.shape:\", out.shape)\n",
    "        out = self.proj(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_size:8, n_embd: 32, head_size: 8\n",
      "block_size:8, n_embd: 32, head_size: 8\n",
      "block_size:8, n_embd: 32, head_size: 8\n",
      "block_size:8, n_embd: 32, head_size: 8\n",
      "<class 'list'>\n",
      "out.shape: torch.Size([4, 8, 32])\n"
     ]
    }
   ],
   "source": [
    "B, T, C= 4, 8, 32\n",
    "block_size = 8\n",
    "n_embd = 32\n",
    "n_head = 4\n",
    "\n",
    "x = torch.randn(B, T, C)\n",
    "ma = MultiHeadAttention(block_size, n_embd, n_head)\n",
    "out = ma(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4, 5, 6]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "tensor([[1, 2, 3, 4, 5, 6],\n",
      "        [1, 2, 3, 4, 5, 6]])\n",
      "tensor([[1, 2],\n",
      "        [1, 2],\n",
      "        [3, 4],\n",
      "        [3, 4],\n",
      "        [5, 6],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# cat function sample\n",
    "tensors = [torch.tensor([[1, 2]]), torch.tensor([[3, 4]]), torch.tensor([[5, 6]])]\n",
    "result = torch.cat(tensors, dim=-1)\n",
    "print(result)\n",
    "# Output: \n",
    "# tensor([[1, 2, 3, 4, 5, 6]])\n",
    "result = torch.cat(tensors, dim=0)\n",
    "print(result)\n",
    "# Output:\n",
    "# tensor([[1, 2],\n",
    "#         [3, 4],\n",
    "#         [5, 6]])\n",
    "\n",
    "\n",
    "\n",
    "# cat function sample\n",
    "tensors = [torch.tensor([[1, 2], [1, 2]]), torch.tensor([[3, 4], [3, 4]]), torch.tensor([[5, 6], [5, 6]])]\n",
    "result = torch.cat(tensors, dim=-1)\n",
    "print(result)\n",
    "# Output: \n",
    "# tensor([[1, 2, 3, 4, 5, 6],\n",
    "#        [1, 2, 3, 4, 5, 6]])\n",
    "result = torch.cat(tensors, dim=0)\n",
    "print(result)\n",
    "# Output:\n",
    "# tensor([[1, 2],\n",
    "#        [1, 2],\n",
    "#        [3, 4],\n",
    "#        [3, 4],\n",
    "#        [5, 6],\n",
    "#        [5, 6]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q: tensor([[-0.7740, -0.0146,  0.2315, -0.1058, -0.4416, -0.5640, -0.3614,  0.1565],\n",
      "        [ 0.3142,  0.6628,  1.0521, -0.4043, -0.0742,  0.8171, -0.4285, -0.2207]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "k: tensor([[ 1.1275,  0.0791,  0.0754,  0.1742,  0.3658, -0.5434,  0.2000, -0.2962],\n",
      "        [-1.0723, -1.2245,  0.2277,  0.2622, -1.3923, -0.3449,  0.3051,  0.1239]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "wei: tensor([[1.0000, 0.0000],\n",
      "        [0.7817, 0.2183]], grad_fn=<SoftmaxBackward0>)\n",
      "v: tensor([[ 0.0613,  0.5328,  0.4237,  0.5995, -0.0622,  0.1780, -0.6394,  0.2454],\n",
      "        [ 0.3002, -0.4567,  0.1420,  0.2841,  1.2245,  0.1776, -0.3756, -0.1101]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "out: tensor([[ 0.0613,  0.5328,  0.4237,  0.5995, -0.0622,  0.1780, -0.6394,  0.2454],\n",
      "        [ 0.1135,  0.3168,  0.3622,  0.5307,  0.2187,  0.1779, -0.5818,  0.1678]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "q: tensor([[ 0.8806,  0.5689,  0.3013, -0.4565,  1.0761,  0.6579,  0.2991,  0.5608],\n",
      "        [ 0.4317,  0.2750,  0.3457, -0.4704,  0.2369, -0.1781, -0.3985, -0.5633],\n",
      "        [ 0.2035,  0.0646, -0.1206, -0.2722,  0.7090, -0.3844,  0.4140,  0.4404]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "k: tensor([[-1.1167, -0.9648,  0.2912,  0.1373, -1.1995,  0.6492, -0.0015, -0.7961],\n",
      "        [ 0.2369, -0.0600,  0.2426, -0.0493,  0.4258, -0.1029,  0.7821,  0.0602],\n",
      "        [-0.1730,  0.3597, -0.2190,  0.2399,  0.1075,  0.2556, -0.2870, -0.5327]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "wei: tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.3479, 0.6521, 0.0000],\n",
      "        [0.0568, 0.7158, 0.2274]], grad_fn=<SoftmaxBackward0>)\n",
      "v: tensor([[ 1.0502, -1.1874,  0.3202,  0.0023,  0.6632, -0.3187, -0.5108,  0.2160],\n",
      "        [-0.2317, -0.5485,  0.0190,  0.2168, -0.3119,  0.7545, -0.4509, -0.4828],\n",
      "        [ 0.5775, -0.3527,  0.1315,  0.0368, -0.3357, -0.0330, -0.4535,  0.2435]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "out: tensor([[ 1.0502, -1.1874,  0.3202,  0.0023,  0.6632, -0.3187, -0.5108,  0.2160],\n",
      "        [ 0.2142, -0.7708,  0.1238,  0.1422,  0.0273,  0.3812, -0.4717, -0.2397],\n",
      "        [ 0.0252, -0.5403,  0.0617,  0.1637, -0.2619,  0.5145, -0.4549, -0.2779]],\n",
      "       grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# simulate generation from a single input token\n",
    "context_len = 8\n",
    "tril = torch.tril(torch.ones(context_len, context_len), diagonal=0)\n",
    "#print(tril)\n",
    "\n",
    "\n",
    "query = nn.Linear(8, 8, bias=False)\n",
    "key = nn.Linear(8, 8, bias=False)\n",
    "value = nn.Linear(8, 8, bias=False)\n",
    "\n",
    "# two input tokens\n",
    "x = torch.randn(2,8)\n",
    "q = query(x)\n",
    "k = key(x)\n",
    "\n",
    "print(\"q:\", q)\n",
    "print(\"k:\", k)\n",
    "\n",
    "wei = q @ k.transpose(-2, -1)\n",
    "# print(\"wei:\", wei)\n",
    "\n",
    "mask = tril[:2, :2]\n",
    "wei = wei.masked_fill(mask == 0, float('-inf'))\n",
    "# print(\"masked wei:\", wei)\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "print(\"wei:\", wei)\n",
    "\n",
    "v = value(x)\n",
    "print(\"v:\", v)\n",
    "out = wei @ v\n",
    "print(\"out:\", out)\n",
    "\n",
    "# three input tokens\n",
    "x = torch.randn(3,8)\n",
    "q = query(x)\n",
    "k = key(x)\n",
    "\n",
    "print(\"q:\", q)\n",
    "print(\"k:\", k)\n",
    "\n",
    "wei = q @ k.transpose(-2, -1)\n",
    "# print(\"wei:\", wei)\n",
    "mask = tril[:3, :3]\n",
    "wei = wei.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "# print(\"masked wei:\", wei)\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "print(\"wei:\", wei)\n",
    "\n",
    "\n",
    "v = value(x)\n",
    "print(\"v:\", v)\n",
    "out = wei @ v\n",
    "print(\"out:\", out)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
