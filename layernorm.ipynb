{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tensor:\n",
      " tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "Output Tensor:\n",
      " tensor([[-1.2247,  0.0000,  1.2247],\n",
      "        [-1.2247,  0.0000,  1.2247]], grad_fn=<NativeLayerNormBackward0>)\n",
      "Mean of Input Tensor: tensor([2., 5.])\n",
      "Variance of Input Tensor: tensor([0.6667, 0.6667])\n",
      "Mean of Output Tensor: tensor([0., 0.], grad_fn=<MeanBackward1>)\n",
      "Variance of Output Tensor: tensor([1.0000, 1.0000], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define input tensor (batch_size=2, features=3)\n",
    "input_tensor = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "\n",
    "# LayerNorm with normalized_shape = number of features (3 in this case)\n",
    "layer_norm = nn.LayerNorm(normalized_shape=3)\n",
    "\n",
    "# Apply LayerNorm\n",
    "output_tensor = layer_norm(input_tensor)\n",
    "\n",
    "print(\"Input Tensor:\\n\", input_tensor)\n",
    "print(\"Output Tensor:\\n\", output_tensor)\n",
    "\n",
    "# mean and variance of the input tensor\n",
    "mean = input_tensor.mean(dim=1)\n",
    "variance = input_tensor.var(dim=1, unbiased=False)\n",
    "print(\"Mean of Input Tensor:\", mean)\n",
    "print(\"Variance of Input Tensor:\", variance)\n",
    "\n",
    "# mean and variance of the output tensor\n",
    "mean = output_tensor.mean(dim=1)\n",
    "variance = output_tensor.var(dim=1, unbiased=False)\n",
    "print(\"Mean of Output Tensor:\", mean)\n",
    "print(\"Variance of Output Tensor:\", variance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon (ϵ): 1e-05\n",
      "Gamma (γ): Parameter containing:\n",
      "tensor([1., 1., 1.], requires_grad=True)\n",
      "Beta (β): Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n",
      "Gamma (γ) requires_grad: True\n",
      "Beta (β) requires_grad: True\n"
     ]
    }
   ],
   "source": [
    "# Access and display epsilon (ϵ), gamma (γ), and beta (β)\n",
    "epsilon = layer_norm.eps  # Epsilon value\n",
    "gamma = layer_norm.weight  # Gamma: learnable scale parameter\n",
    "beta = layer_norm.bias    # Beta: learnable shift parameter\n",
    "\n",
    "print(f\"Epsilon (ϵ): {epsilon}\")\n",
    "print(f\"Gamma (γ): {gamma}\")\n",
    "print(f\"Beta (β): {beta}\")\n",
    "\n",
    "# Check if gamma and beta are learnable\n",
    "print(\"Gamma (γ) requires_grad:\", layer_norm.weight.requires_grad)  # True\n",
    "print(\"Beta (β) requires_grad:\", layer_norm.bias.requires_grad)    # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tensor:\n",
      " tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "Mean:\n",
      " tensor([[2.],\n",
      "        [5.]])\n",
      "Variance:\n",
      " tensor([[0.6667],\n",
      "        [0.6667]])\n",
      "Normalized Tensor:\n",
      " tensor([[-1.2247,  0.0000,  1.2247],\n",
      "        [-1.2247,  0.0000,  1.2247]])\n",
      "Output Tensor (after applying gamma and beta):\n",
      " tensor([[-1.2247,  0.0000,  1.2247],\n",
      "        [-1.2247,  0.0000,  1.2247]])\n"
     ]
    }
   ],
   "source": [
    "# manually calculate the output\n",
    "# Input tensor\n",
    "input_tensor = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "\n",
    "# Define LayerNorm parameters\n",
    "normalized_shape = input_tensor.size(1)  # Number of features\n",
    "eps = 1e-5  # Small constant for numerical stability\n",
    "gamma = torch.ones(normalized_shape)  # Learnable scale (initialized to 1)\n",
    "beta = torch.zeros(normalized_shape)  # Learnable shift (initialized to 0)\n",
    "\n",
    "# Step 1: Compute mean and variance along the last dimension\n",
    "mean = input_tensor.mean(dim=1, keepdim=True)\n",
    "variance = input_tensor.var(dim=1, keepdim=True, unbiased=False)\n",
    "\n",
    "# Step 2: Normalize the input\n",
    "normalized = (input_tensor - mean) / torch.sqrt(variance + eps)\n",
    "\n",
    "# Step 3: Apply gamma and beta\n",
    "output_tensor = normalized * gamma + beta\n",
    "\n",
    "# Display results\n",
    "print(\"Input Tensor:\\n\", input_tensor)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", variance)\n",
    "print(\"Normalized Tensor:\\n\", normalized)\n",
    "print(\"Output Tensor (after applying gamma and beta):\\n\", output_tensor)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.2247) tensor(0.) tensor(1.2247)\n"
     ]
    }
   ],
   "source": [
    "# pure manual calculation\n",
    "mean = (1.0 + 2.0 + 3.0) / 3.0\n",
    "var = ((1.0 - mean) ** 2 + (2.0 - mean) ** 2 + (3.0 - mean) ** 2) / 3.0\n",
    "eps = 1e-5\n",
    "\n",
    "mean = torch.tensor(mean)\n",
    "var = torch.tensor(var)\n",
    "x1 = (1.0 - mean) / torch.sqrt(var + eps)\n",
    "x2 = (2.0 - mean) / torch.sqrt(var + eps)\n",
    "x3 = (3.0 - mean) / torch.sqrt(var + eps)\n",
    "\n",
    "print(x1, x2, x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tensor:\n",
      " tensor([[ 1.,  2.,  3.,  5.,  7.],\n",
      "        [ 4.,  5.,  6., 10., 21.]])\n",
      "Output Tensor:\n",
      " tensor([[-1.2070, -0.7428, -0.2785,  0.6499,  1.5784],\n",
      "        [-0.8331, -0.6729, -0.5127,  0.1282,  1.8905]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "Mean of Input Tensor: tensor([3.6000, 9.2000])\n",
      "Variance of Input Tensor: tensor([ 4.6400, 38.9600])\n",
      "Mean of Output Tensor: tensor([3.5763e-08, 2.3842e-08], grad_fn=<MeanBackward1>)\n",
      "Variance of Output Tensor: tensor([1.0000, 1.0000], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# more test data\n",
    "\n",
    "# Define input tensor (batch_size=2, features=3)\n",
    "input_tensor = torch.tensor([[1.0, 2.0, 3.0, 5.0, 7.0], [4.0, 5.0, 6.0, 10.0, 21.0]])\n",
    "\n",
    "# LayerNorm with normalized_shape = number of features (3 in this case)\n",
    "layer_norm = nn.LayerNorm(normalized_shape=5)\n",
    "\n",
    "# Apply LayerNorm\n",
    "output_tensor = layer_norm(input_tensor)\n",
    "\n",
    "print(\"Input Tensor:\\n\", input_tensor)\n",
    "print(\"Output Tensor:\\n\", output_tensor)\n",
    "\n",
    "# mean and variance of the input tensor\n",
    "mean = input_tensor.mean(dim=1)\n",
    "variance = input_tensor.var(dim=1, unbiased=False)\n",
    "print(\"Mean of Input Tensor:\", mean)\n",
    "print(\"Variance of Input Tensor:\", variance)\n",
    "\n",
    "# mean and variance of the output tensor\n",
    "mean = output_tensor.mean(dim=1)\n",
    "variance = output_tensor.var(dim=1, unbiased=False)\n",
    "print(\"Mean of Output Tensor:\", mean)\n",
    "print(\"Variance of Output Tensor:\", variance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
