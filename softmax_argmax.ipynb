{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/6710cef0-a2e0-8004-a321-5a932b64df44\n",
    "\n",
    "The term **softmax** comes from the fact that this function is a \"softened\" or \"smooth\" version of the **argmax** function.\n",
    "\n",
    "Here's a breakdown of the reasoning:\n",
    "\n",
    "### 1. **Argmax** Function:\n",
    "The **argmax** function returns the index of the largest value in a set of numbers. It is a hard selection, meaning it gives all the \"weight\" or importance to the largest value and completely ignores the rest. For example:\n",
    "\n",
    "```python\n",
    "input = [1.2, 2.5, 0.9]\n",
    "argmax(input) = 1  # Index of the largest value (2.5)\n",
    "```\n",
    "\n",
    "In this case, the function simply returns which number is the largest, discarding any information about how close the other values are.\n",
    "\n",
    "### 2. **Softmax** Function:\n",
    "The **softmax** function, on the other hand, doesn't just pick the largest value. Instead, it assigns a probability to each value in the set, effectively creating a probability distribution over all the inputs. It does this by exponentiating the values and normalizing them so that they sum to 1:\n",
    "\n",
    "$$\n",
    "\\text{softmax}(x_i) = \\frac{e^{x_i}}{\\sum_{j} e^{x_j}}\n",
    "$$\n",
    "\n",
    "The result is a set of probabilities where larger values get more \"weight\" (closer to 1), but smaller values still contribute (closer to 0). It \"softens\" the decision by spreading the probabilities across all values rather than making a hard choice like argmax.\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "input = [1.2, 2.5, 0.9]\n",
    "softmax(input) â‰ˆ [0.186, 0.689, 0.125]\n",
    "```\n",
    "\n",
    "Here, the second value (2.5) gets the highest probability (0.689), but the other values still get non-zero probabilities (0.186 and 0.125), unlike argmax, which would have given all the importance to the largest value.\n",
    "\n",
    "### Why \"Soft\" Max?\n",
    "- The \"max\" part refers to the fact that softmax emphasizes the largest values.\n",
    "- The \"soft\" part means that instead of making a hard decision (like argmax), it provides a probabilistic interpretation where all values contribute to the final outcome.\n",
    "\n",
    "This makes the softmax function especially useful in machine learning (e.g., classification tasks), where it turns raw logits or scores into probabilities that can be interpreted as likelihoods for different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.8015, 0.0656, 0.2691, 0.4464, 0.0272, 0.3675, 0.5111, 0.2905],\n",
      "         [0.7410, 0.3817, 0.8882, 0.7139, 0.4207, 0.8718, 0.3122, 0.8961],\n",
      "         [0.3752, 0.9290, 0.0894, 0.6892, 0.4996, 0.1745, 0.0288, 0.6643],\n",
      "         [0.3624, 0.5696, 0.5459, 0.3901, 0.7961, 0.1889, 0.9403, 0.3936]],\n",
      "\n",
      "        [[0.1792, 0.0530, 0.3544, 0.6321, 0.3019, 0.5378, 0.3212, 0.9155],\n",
      "         [0.6091, 0.5707, 0.5617, 0.2914, 0.3105, 0.9752, 0.2991, 0.5284],\n",
      "         [0.4817, 0.1955, 0.0114, 0.4493, 0.6063, 0.6888, 0.8536, 0.9453],\n",
      "         [0.1196, 0.6693, 0.2814, 0.6272, 0.0117, 0.2868, 0.5020, 0.1766]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "logits = torch.rand(2,4,8)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.1914, 0.0917, 0.1124, 0.1342, 0.0883, 0.1240, 0.1432, 0.1148],\n",
      "         [0.1331, 0.0929, 0.1542, 0.1295, 0.0966, 0.1517, 0.0867, 0.1554],\n",
      "         [0.1130, 0.1965, 0.0849, 0.1546, 0.1279, 0.0924, 0.0799, 0.1508],\n",
      "         [0.1035, 0.1274, 0.1244, 0.1065, 0.1598, 0.0871, 0.1846, 0.1068]],\n",
      "\n",
      "        [[0.0957, 0.0844, 0.1140, 0.1505, 0.1082, 0.1370, 0.1103, 0.1999],\n",
      "         [0.1336, 0.1286, 0.1274, 0.0973, 0.0991, 0.1927, 0.0980, 0.1233],\n",
      "         [0.1143, 0.0859, 0.0714, 0.1107, 0.1295, 0.1406, 0.1658, 0.1818],\n",
      "         [0.0983, 0.1703, 0.1156, 0.1633, 0.0882, 0.1162, 0.1441, 0.1041]]])\n"
     ]
    }
   ],
   "source": [
    "probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n",
      "tensor([[1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "sum = torch.sum(probs, dim=-1)\n",
    "print(sum.shape)\n",
    "print(sum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
