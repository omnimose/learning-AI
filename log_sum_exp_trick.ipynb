{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî∏ Log-Sum-Exp Trick\n",
    "\n",
    "### ‚ùì What is log-sum-exp?\n",
    "\n",
    "The naive computation of:\n",
    "\n",
    "$$\n",
    "\\log\\left( \\sum_{i=1}^{n} e^{z_i} \\right)\n",
    "$$\n",
    "\n",
    "can overflow when $ z_i $ is large (e.g., $ e^{1000} $ üî•).\n",
    "\n",
    "To stabilize this, we use:\n",
    "\n",
    "$$\n",
    "\\log\\left( \\sum_{i=1}^{n} e^{z_i} \\right) = m + \\log\\left( \\sum_{i=1}^{n} e^{z_i - m} \\right)\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "$$\n",
    "m = \\max(z_1, z_2, \\dots, z_n)\n",
    "$$\n",
    "\n",
    "This is the **log-sum-exp trick**.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Purpose of the Log-Sum-Exp Trick\n",
    "\n",
    "- **Numerical stability** when taking logs of sums of exponentials\n",
    "- **Used in**:\n",
    "  - Softmax denominator (`log(‚àë e^z)` in log-softmax)\n",
    "  - Log-likelihood computations\n",
    "  - Energy-based models, variational inference\n",
    "\n",
    "---\n",
    "\n",
    "Let‚Äôs walk through **why** this identity works:\n",
    "\n",
    "$$\n",
    "\\log\\left(\\sum_{i=1}^{n} e^{z_i}\\right) = m + \\log\\left(\\sum_{i=1}^{n} e^{z_i - m}\\right)\n",
    "$$\n",
    "\n",
    "This is known as the **Log-Sum-Exp trick**, and it's super important for **numerical stability**.\n",
    "\n",
    "---\n",
    "\n",
    "### üîß Step-by-step Explanation\n",
    "\n",
    "Let:\n",
    "- $ z = [z_1, z_2, ..., z_n] $\n",
    "- $ m = \\max(z_1, z_2, ..., z_n) $\n",
    "\n",
    "We want to compute:\n",
    "$$\n",
    "\\log\\left(\\sum_{i=1}^{n} e^{z_i} \\right)\n",
    "$$\n",
    "\n",
    "But this might **overflow** if any $ z_i $ is large (e.g. $ z_i = 1000 \\Rightarrow e^{z_i} $ is huge).\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Trick: Factor out the largest value\n",
    "\n",
    "We rewrite the sum by factoring $ e^m $ out of all terms:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} e^{z_i} = e^m \\sum_{i=1}^{n} e^{z_i - m}\n",
    "$$\n",
    "\n",
    "Then apply log:\n",
    "\n",
    "$$\n",
    "\\log\\left( \\sum_{i=1}^{n} e^{z_i} \\right)\n",
    "= \\log\\left( e^m \\sum_{i=1}^{n} e^{z_i - m} \\right)\n",
    "$$\n",
    "\n",
    "Now use the identity:\n",
    "\n",
    "$$\n",
    "\\log(a \\cdot b) = \\log(a) + \\log(b)\n",
    "$$\n",
    "\n",
    "So:\n",
    "\n",
    "$$\n",
    "= \\log(e^m) + \\log\\left( \\sum_{i=1}^{n} e^{z_i - m} \\right)\n",
    "= m + \\log\\left( \\sum_{i=1}^{n} e^{z_i - m} \\right)\n",
    "$$\n",
    "\n",
    "üéâ And that's the trick!\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Why it's stable\n",
    "\n",
    "- **Before**: Large $ z_i $ ‚Üí large $ e^{z_i} $ ‚Üí overflow\n",
    "- **After**: $ z_i - m \\le 0 $ ‚Üí $ e^{z_i - m} \\le 1 $ ‚Üí no overflow\n",
    "\n",
    "Even if `z = [1000, 1001, 1002]`, subtracting `m = 1002` gives `[-2, -1, 0]`, which are totally safe to exponentiate.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1002.4076)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "z = torch.tensor([1000.0, 1001.0, 1002.0])\n",
    "m = torch.max(z)\n",
    "log_sum_exp_stable = m + torch.log(torch.sum(torch.exp(z - m)))\n",
    "print(log_sum_exp_stable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gregorygundersen.com/blog/2020/02/09/log-sum-exp/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
